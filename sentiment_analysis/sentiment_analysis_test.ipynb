{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "test sentiment analysis"
      ],
      "metadata": {
        "id": "fTNSBlYnTFXt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CaV3zhrFHRAo"
      },
      "outputs": [],
      "source": [
        "# all imports\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_HUCFUuTRUW",
        "outputId": "e5f9f88f-108c-488b-8369-7ef3285c1a0c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to sarcasm dataset path in json format\n",
        "dataset_path = '/gdrive/MyDrive/DL_mini_project/datasets/sarcasm.json'\n",
        "\n",
        "if os.path.exists(dataset_path):\n",
        "  print('the path exists')\n",
        "else:\n",
        "  print('Ensure the path is correct.')"
      ],
      "metadata": {
        "id": "90dPVM_KHbJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ea0686-5fcc-40e0-c948-e863cd98d51d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the path exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the test set\n",
        "test_set_path = '/gdrive/MyDrive/DL_mini_project/datasets/test_set_processed.npz'\n",
        "test_data = np.load(test_set_path)"
      ],
      "metadata": {
        "id": "7Thd8_5iXvH_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sepearte it into features and labels\n",
        "test_padded, test_labels = test_data['test_padded'], test_data['test_labels']"
      ],
      "metadata": {
        "id": "77lbAkHgYJ2T"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print shape\n",
        "print(test_padded.shape, test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb-UNYtPYWbq",
        "outputId": "4cfc09dd-070a-4dd0-f7e3-df26675afbc6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4007, 200) (4007,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load teh model from teh json file\n",
        "model_path = '/gdrive/MyDrive/DL_mini_project/Task3/A/model_mlp_architecture.json'\n",
        "\n",
        "\n",
        "with open(model_path, 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "# Create a new model using the loaded architecture\n",
        "model_mlp = tf.keras.models.model_from_json(loaded_model_json)\n",
        "\n",
        "# Compile the loaded model (adjust compilation configuration as needed)\n",
        "model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RRmPzZpXYcDx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIATDn_naCDK",
        "outputId": "0ca192be-36f6-4996-cc90-5229caac65ba"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 200, 100)          500000    \n",
            "                                                                 \n",
            " global_average_pooling1d_2  (None, 100)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               12928     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 523297 (2.00 MB)\n",
            "Trainable params: 523297 (2.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = \"/gdrive/MyDrive/DL_mini_project/Task3/A/weights/model_mlp_weights.h5\"\n",
        "embeddings_matrix_path = \"/gdrive/MyDrive/DL_mini_project/Task3/A/weights/vecs.tsv\""
      ],
      "metadata": {
        "id": "3Fx4_SQWacUg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp.load_weights(weights_path)\n",
        "\n",
        "# Load the pre-trained embeddings from the TSV file\n",
        "embeddings_matrix = np.loadtxt(embeddings_matrix_path, delimiter='\\t')\n",
        "\n",
        "embedding_layer = model_mlp.get_layer('embedding')\n",
        "embedding_layer.set_weights([embeddings_matrix])"
      ],
      "metadata": {
        "id": "X0bVDg_-aEkD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on test_set\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = model_mlp.predict(test_padded)\n",
        "\n",
        "# Convert predictions to binary (0 or 1) based on a threshold (e.g., 0.5)\n",
        "binary_predictions = (predictions > 0.55).astype(int)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(binary_predictions == test_labels)\n",
        "\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZH-KxvibPem",
        "outputId": "cf5638e3-f398-4649-9f8a-6bae30cecd14"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 1s 3ms/step\n",
            "Accuracy on the test set: 51.49%\n"
          ]
        }
      ]
    }
  ]
}